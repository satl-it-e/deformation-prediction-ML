{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHehR6cYOvPc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling3D, BatchNormalization, Dropout, Flatten, concatenate, Reshape, UpSampling3D, Lambda, Conv3D, Conv3DTranspose\n",
    "\n",
    "# from tensorflow_probability.python.layers import MixtureNormal\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHZL9yHTfv9B"
   },
   "source": [
    "Variational AutoEncoder is a combination of an Encoder and a Decoder learning to encode the input instances into a (less dimentional) regularized latent space and to decode them back with minimal reconstruction error. \n",
    "\n",
    "Having a trained VAE we can sample new instances from distribution in the latent space, decompress them and get a quite realistic data instance.\n",
    "\n",
    "For our problem, we use encoder to get the representation of an input shape in the latent space, then concatenate it with the condition vector (e.g. [% coords of the force application point, relative size of applicator, box thickness]) so that it represents a deformed shape in the latent space - and then decode deformed shape representation into a voxel shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKj0vyu0PbnK"
   },
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jGudKp2Pfyj"
   },
   "outputs": [],
   "source": [
    "def get_surface_nodes(file_ids=(1,385)):\n",
    "    X_nodes = []\n",
    "    sample_filenames = glob.glob('./data/sample_model/model/*.json')\n",
    "    for sample_filename in sample_filenames[:len(file_ids)]:\n",
    "        with open(sample_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            surface_node_ids = {d['node_id'] for d in data['surf_elements']}\n",
    "\n",
    "            surface_nodes = {int(node['node_id']): tuple((math.floor(float(value))+1) for (key,value) in node.items() if key in ['x', 'y', 'z']) for node in data['nodes'] if node['node_id'] in surface_node_ids}\n",
    "        X_nodes.append(surface_nodes)\n",
    "    return X_nodes\n",
    "\n",
    "\n",
    "def get_voxel_shapes_from_nodes_dicts(surface_nodes):\n",
    "  X = []\n",
    "  for i in range(len(surface_nodes)):\n",
    "    surface_nodes_coords = set(surface_nodes[i].values())\n",
    "    voxel_grid = [[[int((x,y,z) in surface_nodes_coords) for x in range(100)] for y in range(100)] for z in range(600)]\n",
    "    X.append(voxel_grid)\n",
    "  return X\n",
    "\n",
    "\n",
    "def get_conditions(file_ids=range(1,385)):\n",
    "    X_conditions = []\n",
    "    filenames = glob.glob('cleared_data/pre_*.csv')\n",
    "\n",
    "    for filename in filenames[:len(file_ids)]:\n",
    "        x_cond = dict()\n",
    "        df = pd.read_csv(filename)\n",
    "        x_cond['box_thickness'] = df['a_thickness'][0]\n",
    "        x_cond['volume_relation'] = df['r_l'][0] * df['r_w'][0] * df['r_h'][0]\n",
    "        x_cond['force_application_coord_l'] = df['r_cm_l'][0]  # dist from box-top center to the main point of force application / dist from center to ende along length \n",
    "        x_cond['force_application_coord_w'] = df['r_cm_w'][0]  # ... along  width \n",
    "\n",
    "        X_conditions.append(x_cond)\n",
    "    return X_conditions\n",
    "\n",
    "\n",
    "def get_surface_nodes_dispositions(file_ids=(1,385)):\n",
    "    GT_disps = []  # ground truth\n",
    "    filenames = glob.glob('data/sample_gt/gt/*.csv')\n",
    "    for i, filename in enumerate(filenames[:len(file_ids)]):\n",
    "        df = pd.read_csv(filename)\n",
    "        surface_nodes_dispositions = {row['node_id']:(row['dx'], row['dy'], row['dz']) for (index, row) in df.iterrows()}\n",
    "        GT_disps.append(surface_nodes_dispositions)\n",
    "    return GT_disps\n",
    "\n",
    "\n",
    "def get_disposed_nodes(initial_surface_nodes, surface_nodes_dispositions):\n",
    "    GT_nodes = []\n",
    "    for i in range(len(initial_surface_nodes)):\n",
    "        surface_nodes = dict()\n",
    "        for node_id in initial_surface_nodes[i].keys():\n",
    "            if node_id in initial_surface_nodes[i] and node_id in surface_nodes_dispositions[i]:\n",
    "                surface_nodes[node_id] = tuple(math.ceil(sum(x)) for x in zip(initial_surface_nodes[i][node_id], surface_nodes_dispositions[i][node_id]))\n",
    "        GT_nodes.append(surface_nodes)\n",
    "    return GT_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-1idgRHPBLa"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jM9tbfqBzVdv"
   },
   "outputs": [],
   "source": [
    "voxel_grid_input = Input(shape=(600, 100, 100, 1))  # (batch/None, depth, height, width, channels)\n",
    "cond_vec_input = Input(shape=(4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bl_klqo0XM_l"
   },
   "source": [
    "#### So, we start by defining an Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2sdFq0dftw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 299, 49, 49, 16)   448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 149, 24, 24, 16)   64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 74, 11, 11, 8)     3464      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 37, 5, 5, 8)       32        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 18, 2, 2, 8)       1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 1, 1, 8)        32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 584       \n",
      "=================================================================\n",
      "Total params: 6,360\n",
      "Trainable params: 6,296\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_model = Sequential()\n",
    "\n",
    "enc_model.add(Conv3D(16, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Flatten())\n",
    "\n",
    "enc_model.add(Dense(8, activation='relu'))\n",
    "# enc_model.add(Dense(8, activation='relu', activity_regularizer=tfp.python.layers.MixtureNormal))\n",
    "\n",
    "\n",
    "encoded_box = enc_model(voxel_grid_input)\n",
    "\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsPOSrSUOerf"
   },
   "source": [
    "Now that we have a way to encode sample shapes, we concatenate this representation vector with a condition vector to form a latent representation of a deformed shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIoc_kimYO8O"
   },
   "outputs": [],
   "source": [
    "deformed_box_repr = concatenate([encoded_box, cond_vec_input], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1LFttBMXjha"
   },
   "source": [
    "#### Next, Decoder (future Generator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "qjldjlSwXjvZ",
    "outputId": "046256f9-2410-4efa-8f43-eb0962ea5af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 3, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 5, 5, 7, 16)       448       \n",
      "_________________________________________________________________\n",
      "up_sampling3d (UpSampling3D) (None, 10, 10, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 21, 21, 29, 8)     3464      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3 (None, 42, 42, 58, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 85, 85, 117, 8)    1736      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3 (None, 170, 170, 234, 8)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 341, 341, 469, 8)  1736      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 600, 100, 100)     0         \n",
      "=================================================================\n",
      "Total params: 7,540\n",
      "Trainable params: 7,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deformed_box_vec_input = Input(shape=(deformed_box_repr.shape[-1], ))\n",
    "\n",
    "dec_model = Sequential()\n",
    "\n",
    "dec_model.add(Dense(2*2*3*1*1, activation='relu'))\n",
    "dec_model.add(Reshape((2,2,3,1)))\n",
    "\n",
    "dec_model.add(Conv3DTranspose(16, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "dec_model.add(Reshape((600, 100, 100)))\n",
    "\n",
    "decoded_deformed_box = dec_model(deformed_box_repr)\n",
    "\n",
    "dec_model.summary()\n",
    "\n",
    "assert(len(dec_model.input_shape) == len(deformed_box_repr.shape) == 2)\n",
    "assert(dec_model.input_shape[-1] == deformed_box_repr.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5PJH6Xewni2"
   },
   "source": [
    "### Finally, combine everything into a single VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmVUfN9PwmfT"
   },
   "outputs": [],
   "source": [
    "vae_model = Model(inputs=[voxel_grid_input, cond_vec_input], outputs=decoded_deformed_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ede4b-eGGhLl"
   },
   "source": [
    "VAE model is built. Now we need to define a way to evaluate its performace and enable it to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93jXobqxGhgr"
   },
   "outputs": [],
   "source": [
    "ground_truth_voxel_grid = Input(shape=(600, 100, 100, 1))\n",
    "\n",
    "discr_model = Sequential()\n",
    "\n",
    "discr_model.add(Conv3D(16, (3, 3, 3), strides=(2, 2, 2), activation='relu', input_shape=(600, 100, 100, 1))) \n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Flatten())\n",
    "discr_model.add(Dense(1))\n",
    "\n",
    "discr_output = discr_model(ground_truth_voxel_grid)\n",
    "\n",
    "# Need to make our model of class tf...training.Model in order to use Checkpoint later (because the model class must inherit from a Trackable base).\n",
    "discriminator_model = Model(inputs=[ground_truth_voxel_grid], outputs=discr_output)\n",
    "\n",
    "# print(discr_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4wuHsM0IUL9"
   },
   "source": [
    "## Train our model\n",
    "using https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNpPuTFgPMVg"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'test_percent': 0.2,\n",
    "    'num_samples_total': 383,\n",
    "    'num_samples_using': 5,\n",
    "    'batch_size': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* cross-entropy loss (aka log loss) is measuring difference between probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83SwCBhTt64q"
   },
   "outputs": [],
   "source": [
    "def generator_loss(discriminator_decision):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss between the discriminator's prediction on generated shapes only, and an array of ones.\n",
    "    \"\"\"\n",
    "    return BinaryCrossentropy(tf.ones_like(discriminator_decision), discriminator_decision)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=vae_model,\n",
    "                                 discriminator=discriminator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_q7z-BexY9l"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_shape, x_cond, ground_truth):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        print(\"vae_model.input_shape: \", vae_model.input_shape)\n",
    "        print(\"x [0] = \", len(x_shape[0]))\n",
    "        print(\"X: {} x {} x {} --- Cond: {}\".format(len(x_shape), len(x_shape[0]), len(x_shape[0][0]), len(x_cond)))\n",
    "        print(type(x_shape), type(x_cond))\n",
    "        \n",
    "        generated_deformation = vae_model([[x_shape], [x_cond]], training=True)\n",
    "\n",
    "        real_output = disc_model(ground_truth, training=True)\n",
    "        fake_output = disc_model(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        print(wasserstein_loss(real_output, fake_output))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA4DHnGPy0GB"
   },
   "outputs": [],
   "source": [
    "def train(X, X_cond, Y):\n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        start = time.time()\n",
    "\n",
    "        print(X)\n",
    "        \n",
    "\n",
    "        X, X_cond, Y = X.batch(CONFIG['batch_size']), X_cond.batch(CONFIG['batch_size']), Y.batch(CONFIG['batch_size'])\n",
    "            \n",
    "        for sample in X\n",
    "        for i in range(len(X_cond)):\n",
    "\n",
    "            \n",
    "            X_cond.as_numpy_iterator()\n",
    "            \n",
    "#             print(list(X_cond[i].values()))\n",
    "            print(X[i].shape, len(list(X_cond[i].values())), Y[i].shape)\n",
    "            \n",
    "            train_step(list(X.as_numpy_iterator())[i], list(X_cond.as_numpy_iterator())[i], list(Y.as_numpy_iterator()[i]))\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print('Yay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5Sb0niQ0zUJ2",
    "outputId": "542059a1-a07f-48ad-e128-f31f73e67765"
   },
   "outputs": [],
   "source": [
    "test_ids = np.random.default_rng().choice(range(1, CONFIG['num_samples_total']), math.floor(CONFIG['test_percent'] * CONFIG['num_samples_total']), replace=False)\n",
    "\n",
    "test_ids = set(test_ids)\n",
    "train_ids = set(range(1, CONFIG['num_samples_total'])) - test_ids\n",
    "\n",
    "if CONFIG['num_samples_using']:\n",
    "    train_ids = [train_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    test_ids = [test_ids.pop() for i in range(CONFIG['num_samples_using'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X done\n",
      "cond done\n",
      "Y done\n"
     ]
    }
   ],
   "source": [
    "X_nodes_dicts = get_surface_nodes(train_ids)\n",
    "\n",
    "X = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"X done\")\n",
    "\n",
    "X_cond = get_conditions(train_ids)\n",
    "X_cond = [list(cond.values()) for cond in X_cond]\n",
    "print(\"cond done\")\n",
    "\n",
    "Y_nodes_disp_dicts = get_surface_nodes_dispositions(train_ids)\n",
    "Y_nodes_dicts = get_disposed_nodes(X_nodes_dicts, Y_nodes_disp_dicts)\n",
    "Y = get_voxel_shapes_from_nodes_dicts(Y_nodes_dicts)\n",
    "print(\"Y done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_voxel_grid_into_np(X):\n",
    "    \n",
    "    return [np.reshape(x, (len(x), len(x[0]), len(x[0][0]), 1)) for x in X]  \n",
    "\n",
    "    \n",
    "# Reshape to fit model input.\n",
    "X = reshape_voxel_grid_into_np(X)\n",
    "Y = reshape_voxel_grid_into_np(Y)\n",
    "\n",
    "# Convert into Dataset class in order to use tf.batch function later.\n",
    "train_data = tf.data.Dataset.from_tensor_slices(zip(X, X_cond, Y))\n",
    "\n",
    "# X = tf.data.Dataset.from_tensor_slices(X)\n",
    "# X_cond = tf.data.Dataset.from_tensor_slices(X_cond)\n",
    "# Y = tf.data.Dataset.from_tensor_slices(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0fa603460916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# reshape_arr_to_np(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "a = [[[1,2,3], [11,12,14], [21,22,23]]]\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def get_arr_dim(arr):\n",
    "    depth_i = 0\n",
    "    shape = []\n",
    "    while isinstance(arr, Iterable):\n",
    "        shape.append(len(arr))\n",
    "        arr = arr[0]\n",
    "        depth_i += 1\n",
    "    return depth_i\n",
    "    \n",
    "    \n",
    "print(get_arr_dim(a))\n",
    "\n",
    "def reshape_arr_to_np(arr):\n",
    "    print(range(get_arr_dim(arr)))\n",
    "    shape = tuple(len(arr[i]) for i in range(get_arr_dim(arr)))\n",
    "    print(shape)\n",
    "\n",
    "    \n",
    "# print(a[0], a[1])\n",
    "# reshape_arr_to_np(a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (600, 100, 100, 1), types: tf.int32>\n",
      "[array([[4.00000000e+00, 1.96078431e-03, 3.74107021e-01, 7.46797547e-01],\n",
      "       [4.00000000e+00, 3.92156863e-03, 5.65283492e-01, 7.46797547e-01],\n",
      "       [1.00000000e+00, 1.96078431e-03, 5.65283492e-01, 7.46797547e-01]]), array([[2.00000000e+00, 1.96078431e-03, 3.44695256e-01, 7.46797547e-01],\n",
      "       [1.00000000e+00, 1.58730159e-03, 7.64519508e-01, 7.46797547e-01]])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'BatchDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1e727fe2b1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-b744ff8b6ee0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, X_cond, Y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'BatchDataset' has no len()"
     ]
    }
   ],
   "source": [
    "train(X, X_cond, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpuLsmzzlfV1"
   },
   "outputs": [],
   "source": [
    "Xt_nodes_dicts = get_surface_nodes(test_ids)\n",
    "\n",
    "Xt = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"Xt done\")\n",
    "\n",
    "Xt_cond = get_conditions(test_ids)\n",
    "print(\"t-cond done\")\n",
    "\n",
    "vae_model([Xt[0], Xt_cond[0]], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
