{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHehR6cYOvPc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling3D, Dropout, Flatten, concatenate, Reshape, UpSampling3D, Lambda, Conv3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# from tensorflow_probability.python.layers import MixtureNormal\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "GLOBAL_REL_PATH_TO_DATA = \"../../data\"\n",
    "\n",
    "\n",
    "def get_surface_nodes(file_ids=(1,385)):\n",
    "    X_nodes = []\n",
    "    sample_filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/raw/sample_model/model/*.json')\n",
    "    for sample_filename in sample_filenames[:len(file_ids)]:\n",
    "        with open(sample_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            surface_node_ids = {d['node_id'] for d in data['surf_elements']}\n",
    "\n",
    "            surface_nodes = {int(node['node_id']): tuple((math.floor(float(value))+1) for (key,value) in node.items() if key in ['x', 'y', 'z']) for node in data['nodes'] if node['node_id'] in surface_node_ids}\n",
    "        X_nodes.append(surface_nodes)\n",
    "    return X_nodes\n",
    "\n",
    "\n",
    "def get_voxel_shapes_from_nodes_dicts(surface_nodes):\n",
    "    X = []\n",
    "    for i in range(len(surface_nodes)):\n",
    "        surface_nodes_coords = set(surface_nodes[i].values())\n",
    "        voxel_grid = [[[float((x,y,z) in surface_nodes_coords) for x in range(100)] for y in range(100)] for z in range(600)]\n",
    "        X.append(voxel_grid)\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_conditions(file_ids=range(1,385)):\n",
    "    X_conditions = []\n",
    "    filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/preprocessed/pre_*.csv')\n",
    "    for filename in filenames[:len(file_ids)]:\n",
    "        x_cond = dict()\n",
    "        df = pd.read_csv(filename)\n",
    "        x_cond['box_thickness'] = df['a_thickness'][0]\n",
    "        x_cond['volume_relation'] = df['r_l'][0] * df['r_w'][0] * df['r_h'][0]\n",
    "        x_cond['force_application_coord_l'] = df['r_cm_l'][0]  # dist from box-top center to the main point of force application / dist from center to ende along length\n",
    "        x_cond['force_application_coord_w'] = df['r_cm_w'][0]  # ... along  width\n",
    "\n",
    "        X_conditions.append(x_cond)\n",
    "    return X_conditions\n",
    "\n",
    "\n",
    "def get_surface_nodes_dispositions(file_ids=(1,385)):\n",
    "    GT_disps = []  # ground truth\n",
    "    filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/raw/sample_gt/gt/*.csv')\n",
    "    for i, filename in enumerate(filenames[:len(file_ids)]):\n",
    "        df = pd.read_csv(filename)\n",
    "        surface_nodes_dispositions = {row['node_id']:(row['dx'], row['dy'], row['dz']) for (index, row) in df.iterrows()}\n",
    "        GT_disps.append(surface_nodes_dispositions)\n",
    "    return GT_disps\n",
    "\n",
    "\n",
    "def get_disposed_nodes(initial_surface_nodes, surface_nodes_dispositions):\n",
    "    GT_nodes = []\n",
    "    for i in range(len(initial_surface_nodes)):\n",
    "        surface_nodes = dict()\n",
    "        for node_id in initial_surface_nodes[i].keys():\n",
    "            if node_id in initial_surface_nodes[i] and node_id in surface_nodes_dispositions[i]:\n",
    "                surface_nodes[node_id] = tuple(math.ceil(sum(x)) for x in zip(initial_surface_nodes[i][node_id], surface_nodes_dispositions[i][node_id]))\n",
    "        GT_nodes.append(surface_nodes)\n",
    "    return GT_nodes\n",
    "\n",
    "\n",
    "def get_arr_shape(arr):\n",
    "    shape = []\n",
    "    while isinstance(arr, list):  # enh: use Iterable but fix it for str\n",
    "        print(arr)\n",
    "        shape.append(len(arr))\n",
    "        arr = arr[0]\n",
    "    return tuple(shape)\n",
    "\n",
    "\n",
    "def reshape_voxel_grid_into_np(x_arr):\n",
    "    return [np.reshape(x, get_arr_shape(x)) for x in x_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHZL9yHTfv9B"
   },
   "source": [
    "Variational AutoEncoder is a combination of an Encoder and a Decoder learning to encode the input instances into a (less dimentional) regularized latent space and to decode them back with minimal reconstruction error. \n",
    "\n",
    "Having a trained VAE we can sample new instances from distribution in the latent space, decompress them and get a quite realistic data instance.\n",
    "\n",
    "For our problem, we use encoder to get the representation of an input shape in the latent space, then concatenate it with the condition vector (e.g. [% coords of the force application point, relative size of applicator, box thickness]) so that it represents a deformed shape in the latent space - and then decode deformed shape representation into a voxel shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-1idgRHPBLa"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_42 (Conv3D)           (None, 299, 49, 49, 16)   448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 149, 24, 24, 16)   64        \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 74, 11, 11, 8)     3464      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 37, 5, 5, 8)       32        \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 18, 2, 2, 8)       1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 9, 1, 1, 8)        32        \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 584       \n",
      "=================================================================\n",
      "Total params: 6,360\n",
      "Trainable params: 6,296\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 600, 100, 100, 1) 0         \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (None, 1)                 5849      \n",
      "=================================================================\n",
      "Total params: 5,849\n",
      "Trainable params: 5,785\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, 2, 2, 3, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_32 (Conv3DT (None, 5, 5, 7, 16)       448       \n",
      "_________________________________________________________________\n",
      "up_sampling3d_24 (UpSampling (None, 10, 10, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_33 (Conv3DT (None, 21, 21, 29, 8)     3464      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_25 (UpSampling (None, 42, 42, 58, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_34 (Conv3DT (None, 85, 85, 117, 8)    1736      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_26 (UpSampling (None, 170, 170, 234, 8)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_35 (Conv3DT (None, 341, 341, 469, 8)  1736      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_27 (UpSampling (None, 682, 341, 469, 8)  0         \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 600, 100, 100)     0         \n",
      "=================================================================\n",
      "Total params: 7,540\n",
      "Trainable params: 7,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 600, 100, 10 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 4, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_22 (Sequential)      (None, 8)            6360        input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 4)]          0           input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 12)           0           sequential_22[0][0]              \n",
      "                                                                 tf_op_layer_Squeeze_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_23 (Sequential)      (None, 600, 100, 100 7540        concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 13,900\n",
      "Trainable params: 13,836\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4wuHsM0IUL9"
   },
   "source": [
    "## Train our model\n",
    "using https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNpPuTFgPMVg"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'test_percent': 0.2,\n",
    "    'num_samples_total': 383,\n",
    "    'num_samples_using': 5,\n",
    "    'batch_size': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* cross-entropy loss (aka log loss) is measuring difference between probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83SwCBhTt64q"
   },
   "outputs": [],
   "source": [
    "def generator_loss(discriminator_decision):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss between the discriminator's prediction on generated shapes only, and an array of ones.\n",
    "    \"\"\"\n",
    "    return BinaryCrossentropy(tf.ones_like(discriminator_decision), discriminator_decision)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=vae_model,\n",
    "                                 discriminator=discriminator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_q7z-BexY9l"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_shape, x_cond, ground_truth):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "#         print(\"vae_model.input_shape: \", vae_model.input_shape)\n",
    "#         print(\"x [0] = \", len(x_shape[0]))\n",
    "#         print(\"X: {} x {} x {} --- Cond: {}\".format(len(x_shape), len(x_shape[0]), len(x_shape[0][0]), len(x_cond)))\n",
    "#         print(type(x_shape), type(x_cond))\n",
    "        \n",
    "        x_cond = tf.cast(x_cond, tf.float32)\n",
    "        \n",
    "        generated_deformation = vae_model([\n",
    "            tf.expand_dims(tf.expand_dims(x_shape, axis=0), axis=-1), \n",
    "            tf.expand_dims(tf.expand_dims(x_cond, axis=0), axis=-1)], training=True)\n",
    "\n",
    "        real_output = disc_model(ground_truth, training=True)\n",
    "        fake_output = disc_model(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        print(wasserstein_loss(real_output, fake_output))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA4DHnGPy0GB"
   },
   "outputs": [],
   "source": [
    "def train(X, X_cond, Y):\n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        start = time.time()\n",
    "\n",
    "        print(type(X))\n",
    "        for i in range(len(X)):\n",
    "            train_step(X[i], X_cond[i], Y[i])\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print('Yay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5Sb0niQ0zUJ2",
    "outputId": "542059a1-a07f-48ad-e128-f31f73e67765"
   },
   "outputs": [],
   "source": [
    "test_ids = np.random.default_rng().choice(range(1, CONFIG['num_samples_total']), math.floor(CONFIG['test_percent'] * CONFIG['num_samples_total']), replace=False)\n",
    "\n",
    "test_ids = set(test_ids)\n",
    "train_ids = set(range(1, CONFIG['num_samples_total'])) - test_ids\n",
    "\n",
    "if CONFIG['num_samples_using']:\n",
    "    train_ids = [train_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    test_ids = [test_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X done 5\n",
      "cond done 5\n",
      "Y done 5\n"
     ]
    }
   ],
   "source": [
    "X_nodes_dicts = get_surface_nodes(train_ids)\n",
    "\n",
    "X = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"X done\", len(X))\n",
    "\n",
    "X_cond = get_conditions(train_ids)\n",
    "X_cond = [list(cond.values()) for cond in X_cond]\n",
    "print(\"cond done\", len(X_cond))\n",
    "\n",
    "Y_nodes_disp_dicts = get_surface_nodes_dispositions(train_ids)\n",
    "Y_nodes_dicts = get_disposed_nodes(X_nodes_dicts, Y_nodes_disp_dicts)\n",
    "Y = get_voxel_shapes_from_nodes_dicts(Y_nodes_dicts)\n",
    "print(\"Y done\", len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape to fit model input.\n",
    "# X = reshape_voxel_grid_into_np(X)\n",
    "# Y = reshape_voxel_grid_into_np(Y)\n",
    "\n",
    "X = [tf.convert_to_tensor(x) for x in X]\n",
    "Y = [tf.convert_to_tensor(x) for x in Y]\n",
    "X_cond = [tf.convert_to_tensor(x) for x in X_cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-196-dcc55ae15d2d>:11 train_step  *\n        generated_deformation = vae_model([\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py:281 call\n        outputs = layer(inputs, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py:488 call\n        (array_ops.shape(inputs)[0],) + self.target_shape)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:193 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:7443 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Cannot reshape a tensor with 872572624 elements to shape [1,600,100,100] (6000000 elements) for 'model_14/sequential_23/reshape_17/Reshape' (op: 'Reshape') with input shapes: [1,682,341,469,8], [4] and with input tensors computed as partial shapes: input[1] = [1,600,100,100].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-197-abcd5a478f51>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX_cond\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-182-c68b2fff8683>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(X, X_cond, Y)\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m             \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_cond\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m15\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    566\u001B[0m         \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    567\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 568\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    569\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    570\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    613\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    614\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 615\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    616\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    617\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    495\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    496\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 497\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    498\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    499\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2387\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2388\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2389\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2390\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2391\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   2701\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2702\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2703\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2704\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2705\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   2591\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2592\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2593\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   2594\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2595\u001B[0m         \u001B[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    976\u001B[0m                                           converted_func)\n\u001B[1;32m    977\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 978\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    979\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    980\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 439\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    440\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    966\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    967\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 968\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    969\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    970\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in converted code:\n\n    <ipython-input-196-dcc55ae15d2d>:11 train_step  *\n        generated_deformation = vae_model([\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py:281 call\n        outputs = layer(inputs, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py:488 call\n        (array_ops.shape(inputs)[0],) + self.target_shape)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:193 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:7443 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/anastasiia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Cannot reshape a tensor with 872572624 elements to shape [1,600,100,100] (6000000 elements) for 'model_14/sequential_23/reshape_17/Reshape' (op: 'Reshape') with input shapes: [1,682,341,469,8], [4] and with input tensors computed as partial shapes: input[1] = [1,600,100,100].\n"
     ]
    }
   ],
   "source": [
    "train(X,X_cond,Y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}