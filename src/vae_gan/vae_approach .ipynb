{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHehR6cYOvPc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling3D, Dropout, Flatten, concatenate, Reshape, UpSampling3D, Lambda, Conv3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# from tensorflow_probability.python.layers import MixtureNormal\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sample_data_structure import get_surface_nodes, get_voxel_shapes_from_nodes_dicts, get_conditions, get_surface_nodes_dispositions, get_disposed_nodes, reshape_voxel_grid_into_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHZL9yHTfv9B"
   },
   "source": [
    "Variational AutoEncoder is a combination of an Encoder and a Decoder learning to encode the input instances into a (less dimentional) regularized latent space and to decode them back with minimal reconstruction error. \n",
    "\n",
    "Having a trained VAE we can sample new instances from distribution in the latent space, decompress them and get a quite realistic data instance.\n",
    "\n",
    "For our problem, we use encoder to get the representation of an input shape in the latent space, then concatenate it with the condition vector (e.g. [% coords of the force application point, relative size of applicator, box thickness]) so that it represents a deformed shape in the latent space - and then decode deformed shape representation into a voxel shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-1idgRHPBLa"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bl_klqo0XM_l"
   },
   "source": [
    "voxel_grid_input = Input(shape=(600, 100, 100, 1))  # (batch/None, depth, height, width, channels)\n",
    "cond_vec_input = Input(shape=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2sdFq0dftw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 299, 49, 49, 16)   448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 149, 24, 24, 16)   64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 149, 24, 24, 16)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 74, 11, 11, 8)     3464      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 37, 5, 5, 8)       32        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 5, 5, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 18, 2, 2, 8)       1736      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 1, 1, 8)        32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 1, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 584       \n",
      "=================================================================\n",
      "Total params: 6,360\n",
      "Trainable params: 6,296\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_model = Sequential()\n",
    "\n",
    "enc_model.add(Conv3D(16, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "enc_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "enc_model.add(BatchNormalization(center=True, scale=True))\n",
    "enc_model.add(Dropout(0.5))\n",
    "\n",
    "enc_model.add(Flatten())\n",
    "\n",
    "enc_model.add(Dense(8, activation='relu'))\n",
    "# enc_model.add(Dense(8, activation='relu', activity_regularizer=tfp.python.layers.MixtureNormal))\n",
    "\n",
    "\n",
    "encoded_box = enc_model(voxel_grid_input)\n",
    "\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsPOSrSUOerf"
   },
   "source": [
    "Now that we have a way to encode sample shapes, we concatenate this representation vector with a condition vector to form a latent representation of a deformed shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIoc_kimYO8O"
   },
   "outputs": [],
   "source": [
    "deformed_box_repr = concatenate([encoded_box, cond_vec_input], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1LFttBMXjha"
   },
   "source": [
    "#### Next, Decoder (future Generator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "qjldjlSwXjvZ",
    "outputId": "046256f9-2410-4efa-8f43-eb0962ea5af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 3, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 5, 5, 7, 16)       448       \n",
      "_________________________________________________________________\n",
      "up_sampling3d (UpSampling3D) (None, 10, 10, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 21, 21, 29, 8)     3464      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3 (None, 42, 42, 58, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 85, 85, 117, 8)    1736      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3 (None, 170, 170, 234, 8)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 341, 341, 469, 8)  1736      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 600, 100, 100)     0         \n",
      "=================================================================\n",
      "Total params: 7,540\n",
      "Trainable params: 7,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deformed_box_vec_input = Input(shape=(deformed_box_repr.shape[-1], ))\n",
    "\n",
    "dec_model = Sequential()\n",
    "\n",
    "dec_model.add(Dense(2*2*3*1*1, activation='relu'))\n",
    "dec_model.add(Reshape((2,2,3,1)))\n",
    "\n",
    "dec_model.add(Conv3DTranspose(16, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "dec_model.add(UpSampling3D())\n",
    "dec_model.add(Conv3DTranspose(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "dec_model.add(Reshape((600, 100, 100)))\n",
    "\n",
    "decoded_deformed_box = dec_model(deformed_box_repr)\n",
    "\n",
    "dec_model.summary()\n",
    "\n",
    "assert(len(dec_model.input_shape) == len(deformed_box_repr.shape) == 2)\n",
    "assert(dec_model.input_shape[-1] == deformed_box_repr.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5PJH6Xewni2"
   },
   "source": [
    "### Finally, combine everything into a single VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmVUfN9PwmfT"
   },
   "outputs": [],
   "source": [
    "vae_model = Model(inputs=[voxel_grid_input, cond_vec_input], outputs=decoded_deformed_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ede4b-eGGhLl"
   },
   "source": [
    "VAE model is built. Now we need to define a way to evaluate its performace and enable it to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93jXobqxGhgr"
   },
   "outputs": [],
   "source": [
    "ground_truth_voxel_grid = Input(shape=(600, 100, 100, 1))\n",
    "\n",
    "discr_model = Sequential()\n",
    "\n",
    "discr_model.add(Conv3D(16, (3, 3, 3), strides=(2, 2, 2), activation='relu', input_shape=(600, 100, 100, 1))) \n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='relu'))\n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Conv3D(8, (3, 3, 3), strides=(2, 2, 2), activation='sigmoid'))\n",
    "discr_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "discr_model.add(BatchNormalization(center=True, scale=True))\n",
    "discr_model.add(Dropout(0.5))\n",
    "\n",
    "discr_model.add(Flatten())\n",
    "discr_model.add(Dense(1))\n",
    "\n",
    "discr_output = discr_model(ground_truth_voxel_grid)\n",
    "\n",
    "# Need to make our model of class tf...training.Model in order to use Checkpoint later (because the model class must inherit from a Trackable base).\n",
    "discriminator_model = Model(inputs=[ground_truth_voxel_grid], outputs=discr_output)\n",
    "\n",
    "# print(discr_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4wuHsM0IUL9"
   },
   "source": [
    "## Train our model\n",
    "using https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNpPuTFgPMVg"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'test_percent': 0.2,\n",
    "    'num_samples_total': 383,\n",
    "    'num_samples_using': 5,\n",
    "    'batch_size': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* cross-entropy loss (aka log loss) is measuring difference between probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83SwCBhTt64q"
   },
   "outputs": [],
   "source": [
    "def generator_loss(discriminator_decision):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss between the discriminator's prediction on generated shapes only, and an array of ones.\n",
    "    \"\"\"\n",
    "    return BinaryCrossentropy(tf.ones_like(discriminator_decision), discriminator_decision)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=vae_model,\n",
    "                                 discriminator=discriminator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_q7z-BexY9l"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_shape, x_cond, ground_truth):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        print(\"vae_model.input_shape: \", vae_model.input_shape)\n",
    "        print(\"x [0] = \", len(x_shape[0]))\n",
    "        print(\"X: {} x {} x {} --- Cond: {}\".format(len(x_shape), len(x_shape[0]), len(x_shape[0][0]), len(x_cond)))\n",
    "        print(type(x_shape), type(x_cond))\n",
    "        \n",
    "        generated_deformation = vae_model([[x_shape], [x_cond]], training=True)\n",
    "\n",
    "        real_output = disc_model(ground_truth, training=True)\n",
    "        fake_output = disc_model(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        print(wasserstein_loss(real_output, fake_output))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA4DHnGPy0GB"
   },
   "outputs": [],
   "source": [
    "def train(X, X_cond, Y):\n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        start = time.time()\n",
    "\n",
    "        print(X)\n",
    "        \n",
    "\n",
    "        X, X_cond, Y = X.batch(CONFIG['batch_size']), X_cond.batch(CONFIG['batch_size']), Y.batch(CONFIG['batch_size'])\n",
    "            \n",
    "        for sample in X\n",
    "        for i in range(len(X_cond)):\n",
    "\n",
    "            \n",
    "            X_cond.as_numpy_iterator()\n",
    "            \n",
    "#             print(list(X_cond[i].values()))\n",
    "            print(X[i].shape, len(list(X_cond[i].values())), Y[i].shape)\n",
    "            \n",
    "            train_step(list(X.as_numpy_iterator())[i], list(X_cond.as_numpy_iterator())[i], list(Y.as_numpy_iterator()[i]))\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print('Yay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5Sb0niQ0zUJ2",
    "outputId": "542059a1-a07f-48ad-e128-f31f73e67765"
   },
   "outputs": [],
   "source": [
    "test_ids = np.random.default_rng().choice(range(1, CONFIG['num_samples_total']), math.floor(CONFIG['test_percent'] * CONFIG['num_samples_total']), replace=False)\n",
    "\n",
    "test_ids = set(test_ids)\n",
    "train_ids = set(range(1, CONFIG['num_samples_total'])) - test_ids\n",
    "\n",
    "if CONFIG['num_samples_using']:\n",
    "    train_ids = [train_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    test_ids = [test_ids.pop() for i in range(CONFIG['num_samples_using'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X done\n",
      "cond done\n",
      "Y done\n"
     ]
    }
   ],
   "source": [
    "X_nodes_dicts = get_surface_nodes(train_ids)\n",
    "\n",
    "X = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"X done\")\n",
    "\n",
    "X_cond = get_conditions(train_ids)\n",
    "X_cond = [list(cond.values()) for cond in X_cond]\n",
    "print(\"cond done\")\n",
    "\n",
    "Y_nodes_disp_dicts = get_surface_nodes_dispositions(train_ids)\n",
    "Y_nodes_dicts = get_disposed_nodes(X_nodes_dicts, Y_nodes_disp_dicts)\n",
    "Y = get_voxel_shapes_from_nodes_dicts(Y_nodes_dicts)\n",
    "print(\"Y done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Reshape to fit model input.\n",
    "X = reshape_voxel_grid_into_np(X)\n",
    "Y = reshape_voxel_grid_into_np(Y)\n",
    "\n",
    "# Convert into Dataset class in order to use tf.batch function later.\n",
    "train_data = tf.data.Dataset.from_tensor_slices(zip(X, X_cond, Y))\n",
    "\n",
    "# X = tf.data.Dataset.from_tensor_slices(X)\n",
    "# X_cond = tf.data.Dataset.from_tensor_slices(X_cond)\n",
    "# Y = tf.data.Dataset.from_tensor_slices(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (600, 100, 100, 1), types: tf.int32>\n",
      "[array([[4.00000000e+00, 1.96078431e-03, 3.74107021e-01, 7.46797547e-01],\n",
      "       [4.00000000e+00, 3.92156863e-03, 5.65283492e-01, 7.46797547e-01],\n",
      "       [1.00000000e+00, 1.96078431e-03, 5.65283492e-01, 7.46797547e-01]]), array([[2.00000000e+00, 1.96078431e-03, 3.44695256e-01, 7.46797547e-01],\n",
      "       [1.00000000e+00, 1.58730159e-03, 7.64519508e-01, 7.46797547e-01]])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'BatchDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-1e727fe2b1a7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_cond\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-30-b744ff8b6ee0>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(X, X_cond, Y)\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_cond\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_numpy_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_cond\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'BatchDataset' has no len()"
     ]
    }
   ],
   "source": [
    "train(X, X_cond, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpuLsmzzlfV1"
   },
   "outputs": [],
   "source": [
    "Xt_nodes_dicts = get_surface_nodes(test_ids)\n",
    "\n",
    "Xt = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"Xt done\")\n",
    "\n",
    "Xt_cond = get_conditions(test_ids)\n",
    "print(\"t-cond done\")\n",
    "\n",
    "vae_model([Xt[0], Xt_cond[0]], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}