{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHehR6cYOvPc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling3D, Dropout, Flatten, concatenate, Reshape, UpSampling3D, Lambda, Conv3D, Conv3DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# from tensorflow_probability.python.layers import MixtureNormal\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "GLOBAL_REL_PATH_TO_DATA = \"../../data\"\n",
    "\n",
    "\n",
    "def get_surface_nodes(file_ids=(1,385)):\n",
    "    X_nodes = []\n",
    "    sample_filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/raw/sample_model/model/*.json')\n",
    "    for sample_filename in sample_filenames[:len(file_ids)]:\n",
    "        with open(sample_filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            surface_node_ids = {d['node_id'] for d in data['surf_elements']}\n",
    "\n",
    "            surface_nodes = {int(node['node_id']): tuple((math.floor(float(value))+1) for (key,value) in node.items() if key in ['x', 'y', 'z']) for node in data['nodes'] if node['node_id'] in surface_node_ids}\n",
    "        X_nodes.append(surface_nodes)\n",
    "    return X_nodes\n",
    "\n",
    "\n",
    "def get_voxel_shapes_from_nodes_dicts(surface_nodes):\n",
    "    X = []\n",
    "    for i in range(len(surface_nodes)):\n",
    "        surface_nodes_coords = set(surface_nodes[i].values())\n",
    "        voxel_grid = [[[float((x,y,z) in surface_nodes_coords) for x in range(100)] for y in range(100)] for z in range(600)]\n",
    "        X.append(voxel_grid)\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_conditions(file_ids=range(1,385)):\n",
    "    X_conditions = []\n",
    "    filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/preprocessed/pre_*.csv')\n",
    "    for filename in filenames[:len(file_ids)]:\n",
    "        x_cond = dict()\n",
    "        df = pd.read_csv(filename)\n",
    "        x_cond['box_thickness'] = df['a_thickness'][0]\n",
    "        x_cond['volume_relation'] = df['r_l'][0] * df['r_w'][0] * df['r_h'][0]\n",
    "        x_cond['force_application_coord_l'] = df['r_cm_l'][0]  # dist from box-top center to the main point of force application / dist from center to ende along length\n",
    "        x_cond['force_application_coord_w'] = df['r_cm_w'][0]  # ... along  width\n",
    "\n",
    "        X_conditions.append(x_cond)\n",
    "    return X_conditions\n",
    "\n",
    "\n",
    "def get_surface_nodes_dispositions(file_ids=(1,385)):\n",
    "    GT_disps = []  # ground truth\n",
    "    filenames = glob.glob(GLOBAL_REL_PATH_TO_DATA + '/raw/sample_gt/gt/*.csv')\n",
    "    for i, filename in enumerate(filenames[:len(file_ids)]):\n",
    "        df = pd.read_csv(filename)\n",
    "        surface_nodes_dispositions = {row['node_id']:(row['dx'], row['dy'], row['dz']) for (index, row) in df.iterrows()}\n",
    "        GT_disps.append(surface_nodes_dispositions)\n",
    "    return GT_disps\n",
    "\n",
    "\n",
    "def get_disposed_nodes(initial_surface_nodes, surface_nodes_dispositions):\n",
    "    GT_nodes = []\n",
    "    for i in range(len(initial_surface_nodes)):\n",
    "        surface_nodes = dict()\n",
    "        for node_id in initial_surface_nodes[i].keys():\n",
    "            if node_id in initial_surface_nodes[i] and node_id in surface_nodes_dispositions[i]:\n",
    "                surface_nodes[node_id] = tuple(math.ceil(sum(x)) for x in zip(initial_surface_nodes[i][node_id], surface_nodes_dispositions[i][node_id]))\n",
    "        GT_nodes.append(surface_nodes)\n",
    "    return GT_nodes\n",
    "\n",
    "\n",
    "def get_arr_shape(arr):\n",
    "    shape = []\n",
    "    while isinstance(arr, list):  # enh: use Iterable but fix it for str\n",
    "        print(arr)\n",
    "        shape.append(len(arr))\n",
    "        arr = arr[0]\n",
    "    return tuple(shape)\n",
    "\n",
    "\n",
    "def reshape_voxel_grid_into_np(x_arr):\n",
    "    return [np.reshape(x, get_arr_shape(x)) for x in x_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHZL9yHTfv9B"
   },
   "source": [
    "Variational AutoEncoder is a combination of an Encoder and a Decoder learning to encode the input instances into a (less dimentional) regularized latent space and to decode them back with minimal reconstruction error. \n",
    "\n",
    "Having a trained VAE we can sample new instances from distribution in the latent space, decompress them and get a quite realistic data instance.\n",
    "\n",
    "For our problem, we use encoder to get the representation of an input shape in the latent space, then concatenate it with the condition vector (e.g. [% coords of the force application point, relative size of applicator, box thickness]) so that it represents a deformed shape in the latent space - and then decode deformed shape representation into a voxel shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-1idgRHPBLa"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 2, 2, 3, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_8 (Conv3DTr (None, 5, 5, 7, 16)       448       \n",
      "_________________________________________________________________\n",
      "up_sampling3d_7 (UpSampling3 (None, 10, 10, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_9 (Conv3DTr (None, 21, 21, 29, 8)     3464      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_8 (UpSampling3 (None, 42, 42, 58, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_10 (Conv3DT (None, 85, 44, 60, 8)     1736      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_9 (UpSampling3 (None, 170, 88, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_11 (Conv3DT (None, 340, 102, 122, 4)  2884      \n",
      "_________________________________________________________________\n",
      "up_sampling3d_10 (UpSampling (None, 680, 102, 122, 4)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_12 (Conv3DT (None, 680, 102, 122, 1)  5         \n",
      "_________________________________________________________________\n",
      "cropping3d_2 (Cropping3D)    (None, 600, 100, 100, 1)  0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 600, 100, 100)     0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 600, 100, 100)     0         \n",
      "=================================================================\n",
      "Total params: 8,693\n",
      "Trainable params: 8,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4wuHsM0IUL9"
   },
   "source": [
    "## Train our model\n",
    "using https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNpPuTFgPMVg"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'test_percent': 0.2,\n",
    "    'num_samples_total': 383,\n",
    "    'num_samples_using': 5,\n",
    "    'batch_size': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* cross-entropy loss (aka log loss) is measuring difference between probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83SwCBhTt64q",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(discriminator_decision):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss between the discriminator's prediction on generated shapes only, and an array of ones.\n",
    "    \"\"\"\n",
    "    return BinaryCrossentropy(tf.ones_like(discriminator_decision), discriminator_decision)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "    \n",
    "    print(real_output, fake_output)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    print(real_loss.shape, fake_loss.shape)\n",
    "    print(tf.ones_like(real_output))\n",
    "    \n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    array = real_output.eval(sess)\n",
    "    print (array)\n",
    "    \n",
    "    print(real_loss, fake_loss)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=vae_model,\n",
    "                                 discriminator=discriminator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_q7z-BexY9l"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_shape, x_cond, ground_truth):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "#         print(\"vae_model.input_shape: \", vae_model.input_shape)\n",
    "#         print(\"x [0] = \", len(x_shape[0]))\n",
    "#         print(\"X: {} x {} x {} --- Cond: {}\".format(len(x_shape), len(x_shape[0]), len(x_shape[0][0]), len(x_cond)))\n",
    "#         print(type(x_shape), type(x_cond))\n",
    "        \n",
    "        x_cond = tf.cast(x_cond, tf.float32)\n",
    "        \n",
    "        generated_deformation = vae_model([\n",
    "            tf.expand_dims(tf.expand_dims(x_shape, axis=0), axis=-1), \n",
    "            tf.expand_dims(tf.expand_dims(x_cond, axis=0), axis=-1)], training=True)\n",
    "\n",
    "        real_output = discr_model(tf.expand_dims(tf.expand_dims(ground_truth, axis=-1), axis=0), training=True)\n",
    "        fake_output = discr_model(tf.expand_dims(tf.expand_dims(x_shape, axis=-1), axis=0), training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        print(wasserstein_loss(real_output, fake_output))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, vae_model.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, vae_model.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA4DHnGPy0GB"
   },
   "outputs": [],
   "source": [
    "def train(X, X_cond, Y):\n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        start = time.time()\n",
    "\n",
    "        print(type(X))\n",
    "        for i in range(len(X)):\n",
    "            train_step(X[i], X_cond[i], Y[i])\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    print('Yay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5Sb0niQ0zUJ2",
    "outputId": "542059a1-a07f-48ad-e128-f31f73e67765"
   },
   "outputs": [],
   "source": [
    "test_ids = np.random.default_rng().choice(range(1, CONFIG['num_samples_total']), math.floor(CONFIG['test_percent'] * CONFIG['num_samples_total']), replace=False)\n",
    "\n",
    "test_ids = set(test_ids)\n",
    "train_ids = set(range(1, CONFIG['num_samples_total'])) - test_ids\n",
    "\n",
    "if CONFIG['num_samples_using']:\n",
    "    train_ids = [train_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    test_ids = [test_ids.pop() for i in range(CONFIG['num_samples_using'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X done 5\n",
      "cond done 5\n",
      "Y done 5\n"
     ]
    }
   ],
   "source": [
    "X_nodes_dicts = get_surface_nodes(train_ids)\n",
    "\n",
    "X = get_voxel_shapes_from_nodes_dicts(X_nodes_dicts)\n",
    "print(\"X done\", len(X))\n",
    "\n",
    "X_cond = get_conditions(train_ids)\n",
    "X_cond = [list(cond.values()) for cond in X_cond]\n",
    "print(\"cond done\", len(X_cond))\n",
    "\n",
    "Y_nodes_disp_dicts = get_surface_nodes_dispositions(train_ids)\n",
    "Y_nodes_dicts = get_disposed_nodes(X_nodes_dicts, Y_nodes_disp_dicts)\n",
    "Y = get_voxel_shapes_from_nodes_dicts(Y_nodes_dicts)\n",
    "print(\"Y done\", len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape to fit model input.\n",
    "# X = reshape_voxel_grid_into_np(X)\n",
    "# Y = reshape_voxel_grid_into_np(Y)\n",
    "\n",
    "X = [tf.convert_to_tensor(x) for x in X]\n",
    "Y = [tf.convert_to_tensor(x) for x in Y]\n",
    "X_cond = [tf.convert_to_tensor(x) for x in X_cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Tensor(\"sequential_8/dense_8/BiasAdd:0\", shape=(1, 1), dtype=float32) Tensor(\"sequential_8_1/dense_8/BiasAdd:0\", shape=(1, 1), dtype=float32)\n",
      "() ()\n",
      "Tensor(\"ones_like_2:0\", shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in converted code:\n\n    <ipython-input-40-1b9cb2befea8>:19 train_step  *\n        disc_loss = discriminator_loss(real_output, fake_output)\n    <ipython-input-68-dde8b8de12e9>:18 discriminator_loss  *\n        init = tf.global_variables_initializer()\n\n    AttributeError: module 'tensorflow' has no attribute 'global_variables_initializer'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-69-abcd5a478f51>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX_cond\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-19-c68b2fff8683>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(X, X_cond, Y)\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m             \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_cond\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m15\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    566\u001B[0m         \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    567\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 568\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    569\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    570\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    604\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    605\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 606\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    607\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    608\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2360\u001B[0m     \u001B[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2361\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2362\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2363\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   2701\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2702\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2703\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2704\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2705\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   2591\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2592\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2593\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   2594\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2595\u001B[0m         \u001B[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    976\u001B[0m                                           converted_func)\n\u001B[1;32m    977\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 978\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    979\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    980\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 439\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    440\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    966\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    967\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 968\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    969\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    970\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: in converted code:\n\n    <ipython-input-40-1b9cb2befea8>:19 train_step  *\n        disc_loss = discriminator_loss(real_output, fake_output)\n    <ipython-input-68-dde8b8de12e9>:18 discriminator_loss  *\n        init = tf.global_variables_initializer()\n\n    AttributeError: module 'tensorflow' has no attribute 'global_variables_initializer'\n"
     ]
    }
   ],
   "source": [
    "train(X,X_cond,Y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}